{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f0b023a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271379, 8) (1149780, 3)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "books_df = pd.read_csv('dataset/reviews/BX_Books.csv', sep=';', encoding=\"latin-1\")\n",
    "ratings_df = pd.read_csv('dataset/reviews/BX-Book-Ratings.csv', sep=';', encoding=\"latin-1\")\n",
    "\n",
    "print(books_df.shape, ratings_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fde0934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "            Book-Author  Year-Of-Publication                Publisher  \\\n",
       "0    Mark P. O. Morford                 2002  Oxford University Press   \n",
       "1  Richard Bruce Wright                 2001    HarperFlamingo Canada   \n",
       "2          Carlo D'Este                 1991          HarperPerennial   \n",
       "3      Gina Bari Kolata                 1999     Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                 1999   W. W. Norton & Company   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "366fbb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating\n",
       "0   276725  034545104X            0\n",
       "1   276726  0155061224            5\n",
       "2   276727  0446520802            0\n",
       "3   276729  052165615X            3\n",
       "4   276729  0521795028            6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1add6ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Users: 105283\n",
      "Total Unique Books: 340556\n",
      "Dimensions of Rating Matrix: 105283 * 340556 = 35854757348\n",
      "----------\n",
      "Percentage of matrix filled: 0.0032067711094526078 %\n"
     ]
    }
   ],
   "source": [
    "book_names = books_df.set_index('ISBN')['Book-Title'].to_dict()\n",
    "user_num = len(ratings_df['User-ID'].unique())\n",
    "book_num = len(ratings_df['ISBN'].unique())\n",
    "\n",
    "print(\"Total Unique Users:\", user_num)\n",
    "print(\"Total Unique Books:\", book_num)\n",
    "print(\"Dimensions of Rating Matrix:\", user_num, \"*\", book_num, \"=\", user_num * book_num)\n",
    "print(\"-\"*10)\n",
    "print(\"Percentage of matrix filled:\", 100 * len(ratings_df) / (user_num * book_num), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d93ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import variable\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding modules containing n_users/n_items tensors of size n_factors\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
    "        \n",
    "        # Set weights between 0 and 0.05\n",
    "        self.user_factors.weight.data.uniform_(0, 0.05)\n",
    "        self.item_factors.weight.data.uniform_(0, 0.05)\n",
    "\n",
    "    def forward(self, data):\n",
    "        users, items = data[:, 0], data[:, 1]\n",
    "        return (self.user_factors(users) * self.item_factors(items)).sum(1)\n",
    "    \n",
    "    def predict(self, user, item):\n",
    "        return self.forward(user, item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dec343c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class Loader(Dataset):\n",
    "    def __init__(self):\n",
    "        self.ratings = ratings_df.copy()\n",
    "        \n",
    "        users = ratings_df['User-ID'].unique()\n",
    "        books = ratings_df['ISBN'].unique()\n",
    "                \n",
    "        # Assign unique indices to users and books\n",
    "        self.userid2idx = {o:i for i,o in enumerate(users)}\n",
    "        self.ISBN2idx = {o:i for i,o in enumerate(books)}\n",
    "        \n",
    "        self.ratings['User-ID'] = self.ratings['User-ID'].map(self.userid2idx)\n",
    "        self.ratings['ISBN'] = self.ratings['ISBN'].map(self.ISBN2idx)\n",
    "                \n",
    "        self.x = self.ratings.drop(columns=['Book-Rating']).values\n",
    "        self.y = self.ratings['Book-Rating'].values\n",
    "        self.x, self.y = torch.tensor(self.x, dtype=torch.long), torch.tensor(self.y, dtype=torch.long)\n",
    "        \n",
    "        print(self.x.min(), self.x.max())\n",
    "        print(self.x.shape)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc45da54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n",
      "Using CUDA: True\n",
      "MatrixFactorization(\n",
      "  (user_factors): Embedding(105283, 8)\n",
      "  (item_factors): Embedding(340556, 8)\n",
      ")\n",
      "tensor(0) tensor(340555)\n",
      "torch.Size([1149780, 2])\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device\", device)\n",
    "\n",
    "num_epochs = 128\n",
    "\n",
    "print(\"Using CUDA:\", use_cuda)\n",
    "\n",
    "model = MatrixFactorization(user_num, book_num, n_factors=8)\n",
    "print(model)\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data)\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_set = Loader()\n",
    "train_loader = DataLoader(train_set, 128, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd79e85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a499eaf99f64386b744aa88cd94178c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #0 Loss: 22.041282627586\n",
      "iter #1 Loss: 19.520278633722388\n",
      "iter #2 Loss: 17.563149325980067\n",
      "iter #3 Loss: 16.059341162280596\n",
      "iter #4 Loss: 14.875256335670295\n",
      "iter #5 Loss: 13.912052115260208\n",
      "iter #6 Loss: 13.120258874382538\n",
      "iter #7 Loss: 12.452303497002754\n",
      "iter #8 Loss: 11.892102404425302\n",
      "iter #9 Loss: 11.405688240389297\n",
      "iter #10 Loss: 10.982458861171702\n",
      "iter #11 Loss: 10.605055359627322\n",
      "iter #12 Loss: 10.267695257555705\n",
      "iter #13 Loss: 9.948846753158747\n",
      "iter #14 Loss: 9.65083348845289\n",
      "iter #15 Loss: 9.354555454390042\n",
      "iter #16 Loss: 9.059713491469333\n",
      "iter #17 Loss: 8.750403120803579\n",
      "iter #18 Loss: 8.434027153731959\n",
      "iter #19 Loss: 8.115668919122818\n",
      "iter #20 Loss: 7.811565162370349\n",
      "iter #21 Loss: 7.519286037990965\n",
      "iter #22 Loss: 7.243432227320174\n",
      "iter #23 Loss: 6.976235695250459\n",
      "iter #24 Loss: 6.719543127974861\n",
      "iter #25 Loss: 6.471540992594131\n",
      "iter #26 Loss: 6.231936946075\n",
      "iter #27 Loss: 6.003171642758487\n",
      "iter #28 Loss: 5.783072447997085\n",
      "iter #29 Loss: 5.573446093775522\n",
      "iter #30 Loss: 5.374940601606007\n",
      "iter #31 Loss: 5.1850975148465235\n",
      "iter #32 Loss: 5.006668063456452\n",
      "iter #33 Loss: 4.8357798211441585\n",
      "iter #34 Loss: 4.676233962133442\n",
      "iter #35 Loss: 4.524079011580892\n",
      "iter #36 Loss: 4.380937271482838\n",
      "iter #37 Loss: 4.244634175518235\n",
      "iter #38 Loss: 4.116607150096717\n",
      "iter #39 Loss: 3.9959622787948867\n",
      "iter #40 Loss: 3.8829035113891064\n",
      "iter #41 Loss: 3.7758256112840463\n",
      "iter #42 Loss: 3.6758888729508015\n",
      "iter #43 Loss: 3.580870141155481\n",
      "iter #44 Loss: 3.4936452546258234\n",
      "iter #45 Loss: 3.4097333114582193\n",
      "iter #46 Loss: 3.3331614075186895\n",
      "iter #47 Loss: 3.259860338485813\n",
      "iter #48 Loss: 3.192005841421229\n",
      "iter #49 Loss: 3.128627725782419\n",
      "iter #50 Loss: 3.0697747446056676\n",
      "iter #51 Loss: 3.0133876859060207\n",
      "iter #52 Loss: 2.9609632277746156\n",
      "iter #53 Loss: 2.9119744411784025\n",
      "iter #54 Loss: 2.8669618189925408\n",
      "iter #55 Loss: 2.8235324200590695\n",
      "iter #56 Loss: 2.783326782230597\n",
      "iter #57 Loss: 2.7452368095830675\n",
      "iter #58 Loss: 2.709571566976392\n",
      "iter #59 Loss: 2.6758477240817444\n",
      "iter #60 Loss: 2.6444284131104148\n",
      "iter #61 Loss: 2.6145823675474347\n",
      "iter #62 Loss: 2.5859053725656445\n",
      "iter #63 Loss: 2.5602264391756213\n",
      "iter #64 Loss: 2.534941572562021\n",
      "iter #65 Loss: 2.511214131981443\n",
      "iter #66 Loss: 2.4887301775005923\n",
      "iter #67 Loss: 2.467215116957202\n",
      "iter #68 Loss: 2.4473448990647517\n",
      "iter #69 Loss: 2.427754175586025\n",
      "iter #70 Loss: 2.4095795460922025\n",
      "iter #71 Loss: 2.3918309279344374\n",
      "iter #72 Loss: 2.3758152214022106\n",
      "iter #73 Loss: 2.359221647235077\n",
      "iter #74 Loss: 2.3435835096229094\n",
      "iter #75 Loss: 2.3289482598446476\n",
      "iter #76 Loss: 2.3149218837813836\n",
      "iter #77 Loss: 2.301284646126657\n",
      "iter #78 Loss: 2.2884984324693174\n",
      "iter #79 Loss: 2.276047077175505\n",
      "iter #80 Loss: 2.264172713743689\n",
      "iter #81 Loss: 2.252614387601438\n",
      "iter #82 Loss: 2.2415346763194517\n",
      "iter #83 Loss: 2.2308115125445602\n",
      "iter #84 Loss: 2.220128971159783\n",
      "iter #85 Loss: 2.211120789478102\n",
      "iter #86 Loss: 2.201107332392736\n",
      "iter #87 Loss: 2.1920541676104923\n",
      "iter #88 Loss: 2.1829261819862196\n",
      "iter #89 Loss: 2.1743230849627224\n",
      "iter #90 Loss: 2.165788580092558\n",
      "iter #91 Loss: 2.1575967578185664\n",
      "iter #92 Loss: 2.150049899570079\n",
      "iter #93 Loss: 2.1417824153637124\n",
      "iter #94 Loss: 2.135310995732041\n",
      "iter #95 Loss: 2.1276686733693704\n",
      "iter #96 Loss: 2.121096056659278\n",
      "iter #97 Loss: 2.113487830694728\n",
      "iter #98 Loss: 2.1077179685707788\n",
      "iter #99 Loss: 2.1009262250915715\n",
      "iter #100 Loss: 2.095039163090452\n",
      "iter #101 Loss: 2.0884947042966573\n",
      "iter #102 Loss: 2.0824078824443673\n",
      "iter #103 Loss: 2.076749115790846\n",
      "iter #104 Loss: 2.071240774539854\n",
      "iter #105 Loss: 2.065428414466744\n",
      "iter #106 Loss: 2.060419674773239\n",
      "iter #107 Loss: 2.0548117247918234\n",
      "iter #108 Loss: 2.049843649081633\n",
      "iter #109 Loss: 2.0449964878395352\n",
      "iter #110 Loss: 2.0400755109924207\n",
      "iter #111 Loss: 2.0354537454875503\n",
      "iter #112 Loss: 2.031434701065782\n",
      "iter #113 Loss: 2.0263007834336415\n",
      "iter #114 Loss: 2.0218262826727558\n",
      "iter #115 Loss: 2.017082818178455\n",
      "iter #116 Loss: 2.013123447149511\n",
      "iter #117 Loss: 2.0088435466326944\n",
      "iter #118 Loss: 2.004936293867321\n",
      "iter #119 Loss: 2.0004101516966113\n",
      "iter #120 Loss: 1.996961733270538\n",
      "iter #121 Loss: 1.9931742300517998\n",
      "iter #122 Loss: 1.98940748975575\n",
      "iter #123 Loss: 1.9854961619715004\n",
      "iter #124 Loss: 1.9816379689943362\n",
      "iter #125 Loss: 1.9785732191674337\n",
      "iter #126 Loss: 1.9750700736449263\n",
      "iter #127 Loss: 1.9712887138947737\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(num_epochs)):\n",
    "    losses = []\n",
    "    for x, y in train_loader:\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = loss_func(outputs.squeeze(), y.type(torch.float32))\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    \n",
    "    print(f\"iter #{i}\", \"Loss:\", sum(losses) / len(losses))\n",
    "\n",
    "torch.save(model.state_dict(), \"models/collaborative_filtering.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
